# -*- coding: utf-8 -*-
"""Projeto_dados_alura.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/144-8g4S-c-cLU8NPBKYVShitZBDvlF9_

**Notebook para Imersão Dados Alura**
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.dummy import DummyClassifier
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier

"""**Coleta do dataset de experimentos biológicos**"""

path='https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_experimentos.zip?raw=true'
dados=pd.read_csv(path, compression='zip')
dados

"""---

**Dataset: 23814 registros com 877 features**

Descrição da aplicação de determinada droga em culturas de células.
"""

dados.head()
dados.tail()
dados.describe()
dados.info()
dados.shape

var='tratamento' #tipo de tratamento utilizado
dados[var] #dataseries
print('Total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts(normalize=True))) #feature com valores desbalanceados, onde grupo com droga apresenta muito mais dados
print('Classes de valores únicos da feature %s:\n %s\n'  % (var, dados[var].unique())) #descrição dos valores únicos de uma feature, no caso tratamento: registros divididos em dois grupos, controle e teste
ax=dados['tratamento'].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)

var='tempo' #tempo ministrando a droga
dados[var] #dataseries
print('Total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts(normalize=True))) #feature com dados mais bem balanceados em relação à feature anterior tratamento
print('Classes de valores únicos da feature %s:\n %s\n'  % (var, dados[var].unique())) #descrição dos valores únicos de uma feature: registros divididos em três grupos de tempo
ax=dados[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)

var='dose' #dose ministrada
dados[var] #dataseries
print('Total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts(normalize=True))) #feature com dados balanceados
print('Classes de valores únicos da feature %s:\n %s\n'  % (var, dados[var].unique())) #descrição dos valores únicos de uma feature: registros divididos em dois grupos de doses aplicadas
ax=dados[var].value_counts().plot.bar()
ax.set_title('Distribuição de valores para a feature '+var)

var='droga' #tipo de droga ministrada, dados provavelmente anonimizados para evitar vieses de análise
dados[var] #dataseries
print('Total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts(normalize=True))) #feature com dados balanceados
print('Classes de valores únicos da feature %s:\n %s\n'  % (var, dados[var].unique())) #descrição dos valores únicos de uma feature: 3289 tipos diferentes de drogas ministradas
print('Total de valores únicos da feature %s:\n %i\n'  % (var, len(dados[var].unique())))

"""**Utilização do Seaborn:**

Análise de drogas aplicadas nos experimentos.

Drogas representam compostos químicos. Por isso a alteração do nome da feature droga por composto, o qual representa melhor a classe.
"""

sns.set()
plt.figure(figsize=(10, 8))

dados_novos=dados.rename(columns={'droga':'composto'}) #criação de um novo df contendo a alteração no nome da feature droga
dados_novos.columns

var='composto'
compostos=dados_novos[var].value_counts().index[:5] #índice de compostos aplicadas com maior frequência
print(compostos)

dados_novos.query('composto in @compostos') #registros contendo apenas os compostos de maior frequência

ax=sns.countplot(x='composto', data=dados_novos.query('composto in @compostos'))
ax.set_title('5 Compostos de Maior Frequência')
plt.show()

#especificação de condições para os valores de dados dentro de features
#dados_novos[dados_novos['tratamento']=='com_droga']
#dados_novos[dados_novos['tempo']==24]

"""---

**Análise das features que descrevem os *genes*, na forma g-X, onde X representa o índice de um dado gene:**

**Gene representa um fragmento de DNA, por exemplo 'g-0': O valor da feature 'g-0' descreve a expressão gênica do gene 0 de um dado registro.**

Expresão gênica normal representa a geração de 4 RNAs (1x) (RNA mensageiro) que carregam a informação necessária à síntese da proteína que ocorre fora do núcleo da célula. 

O RNA conduz as informações gênicas do DNA de dentro do núcleo da célula para fora do núcleo, onde a síntese proteica ocorre.

Expressão gênica corresponde a geração de RNAs pela célula para que a síntese proteica ocorra. 

Expressao gênica normal gera 4 RNAs (1x), expressões alteradas devidos a outros estimulos na célula geram outras quatidades de RNAs. Por exemplo, 8 RNAs gerados representa uma expressão gênica 2x da normal.
"""

var='g-0' #gene 0, o valor da feature descreve a expressão gênica do gene 0, dados provavelmente normalizados
dados_novos[var] #dataseries
print('Total de valores da feature %s:\n %s\n' % (var, dados_novos[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n %s\n' % (var, dados_novos[var].value_counts(normalize=True)))
print('Classes de valores únicos da feature %s:\n %s\n'  % (var, dados_novos[var].unique())) #descrição dos valores únicos de uma feature
print('Total de valores únicos da feature %s:\n %i\n'  % (var, len(dados_novos[var].unique())))

"""**Análise geral de genes:**

Os genes utilizados nos experimentos são descritos como uma sequência de identificadores inteiros, iniciando em g-0 até g-771, resultando em 772 tipos diferentes de genes.

Todas as features de genes possuem valores, não há incidência de valores nulos ou faltantes em nenhuma das 772 features de genes. Os valores em cada feature representam o nível de expressão gênica de determinado gene e certo experimento.
"""

#descobrindo todas as fetures de genes
id_genes=[]
for i in dados_novos.columns:
  if i[:2] == 'g-':
    id_genes.append(i)
print('Total de tipos de genes analisados:', len(id_genes), '\n')

for gen in id_genes:
  print('Total de valores únicos da feature (gene) %s: %i de %i'  % (gen, len(dados_novos[gen].unique()), len(dados_novos[gen])))

"""**Histograma para análise de genes:**

Análise da distribuição de valores de um dado gene, por exemplo gene g-0.

Nota-se a distribuição em torno do 0, o que reforça a normalização de valores. Além disso, visualmente g-0 tende a apresentar distribuição normal em torno do valor 0.
"""

dados_novos['g-0'].min(), dados_novos['g-0'].max()
dados_novos['g-0'].hist(bins=50)

#descrição analítica de todos os genes 
dados_novos.loc[:,id_genes[0]:id_genes[-1]].describe()

"""**Histograma das medidas de posição dos valores de cada gene:**

**Média:** A distribuição das médias de todos os valores de cada gene segue a distribuição normal, concentrando-se em média próxima ao valor 0. Contudo, percebe-se que os valores de cada gene podem diferir já que alguns apresentam médias distintas.

**Mediana:** A mediana dos valores de cada gene tende a concentrar-se no valor 0. Nesse, a mediana em 0 indica que 50% dos valores de expressão gênica para um certo gene possuem valores acima de 0 e os outros 50% possuem valores abaixo de 0. 

**Valores mínimos e máximos:** Em relação aos valores mínimos e máximos de cada gene, nota-se grande concentração dos genes em ambos os limites. Indicação de normalização de valores utilizando -10 e 10 como intervalos de corte. Contudo, já que os valores originais não foram fornecidos, o método e a forma de normalização acaba tornando-se irrelevante pela falta de informação.

Já a relação entre os valores (nível de expressão gênica) de um certo gene ou entre genes para um certo registro (experimento) importam, e estão reportados no df para possibilitar análises de expressão entre genes ou experimentos distintos.
"""

dados_novos.loc[:,id_genes[0]:id_genes[-1]].describe().T['mean'].hist(bins=50)

dados_novos.loc[:,id_genes[0]:id_genes[-1]].describe().T['50%'].hist(bins=50)

dados_novos.loc[:,id_genes[0]:id_genes[-1]].describe().T['min'].hist(bins=50)

dados_novos.loc[:,id_genes[0]:id_genes[-1]].describe().T['max'].hist(bins=50)

"""---

**Análise das features que descrevem as linhagens celulares, representadas na forma c-X, onde X representa o índice de uma linhagem:**

Cada *c* representa uma linhagem celular, que pode ser, por exemplo, a linhagem de um câncer específico, linhagem de células saudáveis de órgãos específicos, etc.

O objetivo de incluir diversas linhagens de células em cada registro consiste em garantir que a análise não fique enviesada para apenas um tipo de linhagem celular. Os vários *c's* cobrem várias linhagens. 

Os valores da feature 'c-0' descrevem a resposta da linhagem celular identificada em 0 para cada experimento realizado, no caso considerando a influência de determinada droga ministrada. A resposta representa a viabilidade desse tipo celular ao tratamento, ou seja, a sobrevivência das celulas.
"""

var='c-0' #linhagem 0
dados_novos[var] #dataseries
print('Total de valores da feature %s:\n %s\n' % (var, dados_novos[var].value_counts()))
print('Porcentagem total de valores da feature %s:\n %s\n' % (var, dados_novos[var].value_counts(normalize=True)))
print('Classes de valores únicos da feature %s:\n %s\n'  % (var, dados_novos[var].unique())) #descrição dos valores únicos de uma feature
print('Total de valores únicos da feature %s:\n %i\n'  % (var, len(dados_novos[var].unique())))

"""**Análise geral das linhagens celulares:**

As linhagens celulares utilizadas nos experimentos são descritas como uma sequência de identificadores inteiros, iniciando em c-0 até c-99, resultando em 100 tipos diferentes de células.

Todas as features de linhagens possuem valores, não há incidência de valores nulos ou faltantes em nenhuma das 100 features de genes. 

Os valores em cada feature representam a resposta de determinada linhagem ou tipo celular a um certo experimento.
"""

#descobrindo todas as features de tipos celulares
id_linhagens=[]
for i in dados_novos.columns:
  if i[:2] == 'c-':
    id_linhagens.append(i)
print('Total de tipos de genes analisados:', len(id_linhagens), '\n')

for lin in id_linhagens:
  print('Total de valores únicos da feature (gene) %s: %i de %i'  % (lin, len(dados_novos[lin].unique()), len(dados_novos[lin])))

"""**Histograma para análise de tipos celulares:**

Análise da distribuição de valores de um dado tipo celular, por exemplo gene c-0.

Nota-se a distribuição de valores em torno do 0. Os valores de c-0, visualmente tendem a apresentar distribuição normal em torno do valor 0.
"""

dados_novos['c-0'].min(), dados_novos['c-0'].max()
dados_novos['c-0'].hist(bins=50)

#descrição analítica de todos os genes 
dados_novos.loc[:,id_linhagens[0]:id_linhagens[-1]].describe()

"""**Histograma das medidas de posição dos valores de cada linhagem celular:**

**Média,** 
**Mediana,** 
**Valores mínimos e máximos.**
"""

dados_novos.loc[:,id_linhagens[0]:id_linhagens[-1]].describe().T['mean'].hist(bins=50)

dados_novos.loc[:,id_linhagens[0]:id_linhagens[-1]].describe().T['50%'].hist(bins=50)

dados_novos.loc[:,id_linhagens[0]:id_linhagens[-1]].describe().T['min'].hist(bins=50)

dados_novos.loc[:,id_linhagens[0]:id_linhagens[-1]].describe().T['max'].hist(bins=50)

"""**Boxplot com Seaborn:**

Valores da linhagem celular *c-0*.
"""

sns.boxplot(x='c-0', data=dados_novos)

"""**Boxplot com Seaborn:**

Valores do gene *g-0*.

Valores do gene g-0, dividindo registros de acordo com o tratamento utilizado (com droga ou sem droga (com controle)).
"""

sns.set()
plt.figure(figsize=(10, 8))
sns.boxplot(x='g-0', data=dados_novos)
sns.boxplot(y='g-0', x='tratamento', data=dados_novos)

"""---

**Relação entre variáveis:**

Tabela de frequências para relacionar variáveis de um dataset.

Lib. Pandas Crosstab: https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html

*"Compute a simple cross tabulation of two (or more) factors. By default computes a frequency table of the factors unless an array of values and an aggregation function are passed."*
"""

dados_novos

"""**Relação entre features: Número de registros relacionando features**

Tratamento: grupos controle e com droga 

> X

Dose: duas doses D1 e D2

> X

Tempo: 3 tempos de aplicação 24, 48 e 71.

Observa-se através dessa relação entre as três variáveis que as categorias internas aos dois grandes grupos (controle e com droga) aparentam estarem balanceados. Através da normalização por índice o balanceamento fica melhor ilustrado.

Contudo, o número de dados em cada um desses grandes grupos estão desbalanceados, visto que o grupo controle apresenta 1866 registros e o grupo com droga apresenta 21948 dados.
"""

var='tratamento'
print('Total de valores da feature %s:\n %s\n' % (var, dados[var].value_counts()))
pd.crosstab([dados_novos['dose'], dados_novos['tempo']], dados_novos['tratamento'], normalize='index')

"""Agregando ao crosstab informação extra de outra feature através da relação entre dose, tempo e tratamento. 

No caso, a média de *g-0* em cada um dos grupos formados. 

Por exemplo, observa-se o aumento da expressão de g-0 no grupo com droga comparado ao controle. 

Também existem indícios que a dose 1 aumentou a expressão em relação à dose 2. 

Observa-se também que o tempo 48 tendeu a aumentar a expressão em relação ao menor tempo de 24. Contudo, talvez não existam diferenças de expressão entre os dois maiores tempos (48 e 72).

Testes estatísticos nesse são necessários para comprovar tais hipóteses e avaliar se as amostras diferem ou não significativamente.
"""

pd.crosstab([dados_novos['dose'], dados_novos['tempo']], dados_novos['tratamento'], values=dados_novos['g-0'], aggfunc='mean')

pd.crosstab([dados_novos['dose'], dados_novos['tempo']], dados_novos['tratamento'], values=dados_novos['g-0'], aggfunc='sum')

"""**Desafio: Criar tabela de frequências com o pandas.groupby().**

Utilizando a relação entre as features tratamento, dose e tempo, o groupby através da média mostra os valores médios para as features numéricas (g-X e c-X) de cada grupo formado a partir dessa relação.
"""

dados_novos.groupby(['tratamento', 'dose', 'tempo']).mean()

"""**Análise de expressão considerando a mesma relação anterior para os dois compostos de maior ocorrência:**"""

var='composto'
compostos=dados_novos[var].value_counts().index[:2] #compostos com maiores frequências
#print(compostos)

dados_composto=dados_novos.query('composto in @compostos') #registros contendo apenas os dois compostos de maiores frequências
dados_composto.groupby(['tratamento', 'dose', 'tempo', 'composto']).mean()

"""**Desafio: Criar tabela de frequências com o pandas.melt().**

Utilizando a relação entre as features tratamento, dose e tempo, o melt exibe os valores para a feature *g-0* de cada grupo formado a partir dessa relação.
"""

pd.melt(dados_novos, id_vars=['tratamento', 'dose', 'tempo'], value_vars=['g-0'])

"""**Gráfico de dispersão para análise de relação entre variáveis:**

Analisando a distribuição de valores para as features g-0 e g-3, não e possível perceber nenhum tipo de padrão entre os valores (sem correlação).
"""

#dados_novos.loc[:,['g-0','g-3']]
sns.scatterplot(x='g-0', y='g-3', data=dados_novos[['g-0', 'g-3']])

"""Contudo, analisando a distribuição de valores para as features g-0 e g-8, já observa-se um padrão mais definido. Nota-se uma tendência de queda nos valores de g-8 a medida em que os valores de g-0 aumentam (correlação negativa)."""

sns.scatterplot(x='g-0', y='g-8', data=dados_novos[['g-0', 'g-8']])

sns.lmplot(x='g-0', y='g-8', data=dados_novos, line_kws={'color':'red'}, col='tratamento', row='tempo')

"""**Correlação entre variáveis:**

O objetivo do estudo da correlação é determinar o grau de relacionamento entre duas variáveis. Caso os pontos das variáveis, representados num plano cartesiano (x, y) ou gráfico de dispersão, apresentem uma dispersão ao longo de uma reta imaginária, dizemos que os dados apresentam uma correlação linear que pode ser negativa (-1) ou positiva (1).

Correlação totalmente positiva (1): Os valores de ambas as variáveis apresentam comportamentos muito semelhantes. Por exemplo, a medida em que um aumenta o outro aumenta também.

Correlação totalmente negativa (-1): Os valores de ambas as variáveis apresentam comportamentos muito semelhantes, mas são inversamente correlacionados. Por exemplo, a medida em que um aumenta o outro diminui.

Sem correlação (0): Os valores de ambas as variáveis nao apresentam comportamentos semelhantes.

Analisando as relações dos gráficos de dispersão anteriores, observa-se que g-0 e g-3 apresentam correlação de 0.011, o que atesta que as variáveis não estão correlacionadas.

Já g-0 e g-8 apresentam correlação de -0.604, comprovando a correlação negativa entre as variáveis.

**Porém, correlação não implica em caudalidade.**

O fato de variáveis estarem correlacionados não quer dizer que uma influêncie no comportamento da outra. O padrão de comportamento pode estar associado a fatores externos sem relação entre si.
"""

dados_novos.loc[:, id_genes[0]:id_genes[-1]].corr()

"""**Plotagem das correlações:**

https://seaborn.pydata.org/examples/many_pairwise_correlations.html

Geração da matriz diagonal de correlação entre variáveis de genes.
"""

# Compute the correlation matrix
#corr = dados_novos.loc[:, id_genes[0]:id_genes[-1]].corr()
corr = dados_novos.loc[:, 'g-0':'g-50'].corr()

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

"""Geração da matriz diagonal de correlação entre variáveis de linhagens celulares.

Observa-se a alta correlação entre os valores dos diferentes tipos celulares, diferentemente dos genes.
"""

# Compute the correlation matrix
#corr = dados_novos.loc[:, id_genes[0]:id_genes[-1]].corr()
corr = dados_novos.loc[:, 'c-0':'c-50'].corr()

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

"""**Correlação entre genes e tipos celulares:**"""

dados_novos.iloc[:, np.r_[5:55,772:822]].corr()

# Compute the correlation matrix
corr=dados_novos.iloc[:, np.r_[5:55,772:822]].corr()

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

"""**Análise do dataset de Resultados:**

Cada feature representa um mecanismo de ação de um composto sobre os alvos (experimentos) do dataset anterior.

Droga agonista: ativa o receptor.

Droga antagonista: inibe o receptor.

Valor 1 para um mecanismo indica que esse mecanismo foi ativado em dado experimento. 0 indica não ativação do mecanismo.

As linhas representam os experimentos do dataset anterior indicando quais mecanismos de ativação foram ativados pelos experimentos.
"""

dados_resultados=pd.read_csv('https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_resultados.csv?raw=true')
dados_resultados.shape
dados_resultados.head()

dados_resultados['acat_inhibitor'].unique()

dados_resultados['5-alpha_reductase_inhibitor'].unique()

#seleção de colunas pelo tipo e aplicação de função agregadora em cada feature (mecanismo de ativação)
contagem_moa=dados_resultados.select_dtypes('int64').sum().sort_values(ascending=False) #número de vezes que os mecanismos (moa) foram ativados
contagem_moa

#descarte de coluna ao invés da seleção
contagem_moa=dados_resultados.drop('id', axis=1).sum().sort_values(ascending=False) #número de vezes que os mecanismos (moa) foram ativados
contagem_moa

dados_resultados.drop('id', axis=1).sum(axis=1) #soma de ativações por experimento (registros do dataset)

"""**Relacionando experimentos que ativaram e não ativaram MOAs:**

Para relacionar informações de dois datasets é necessário juntá-los (merge) para a realização das análises.

Grupo controle não deveria ativar MOAs, enquanto grupo com droga espera-se que ative algum MOAs. A não ativação em um experimento com droga pode indicar a ineficácia do composto nesse cenário testado.
"""

dados_resultados['n_moa']=dados_resultados.drop('id', axis=1).sum(axis=1)

dados_resultados['ativo_moa']=dados_resultados['n_moa']!=0
dados_resultados.head()

"""**Merge de DataFrames:**

https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html

Combinando as tabelas de experimentos e de resultados dos mecanismos ativados.
"""

dados_combinados=pd.merge(dados_novos, dados_resultados[['id', 'n_moa', 'ativo_moa']], on='id') #on representa a chave primária da tabela criada
dados_combinados.head()

dados_combinados.query('tratamento=="com_controle"')['ativo_moa'].unique() #nenhum MOA foi ativado no grupo controle, o que era esperado

dados_combinados.query('tratamento=="com_droga"')['ativo_moa'].value_counts() #vários experimentos não ativaram nenhum MOA

"""**Efeito dos compostos de maior ocorrência sobre o gene 0, indicando se houve ativação ou não de algum MOA:**"""

compostos_principais=dados_combinados['composto'].value_counts().index[:11]
plt.figure(figsize=(12, 8))
sns.boxplot(data=dados_combinados.query('composto in @compostos_principais'), x='composto', y='g-0', hue='ativo_moa')

"""**Desafio: Criar coluna eh_controle?**

**Desafio: Criar três colunas dizendo se é 24h, 48h ou 72h em relação ao tempo**

**Desafios 5 a 7 da aula 4**
"""

dados_combinados['eh_controle']=dados_combinados['tratamento']=='com_controle'
dados_combinados['tempo_24']=(dados_combinados['tempo']==24).astype(int) 
dados_combinados['tempo_48']=(dados_combinados['tempo']==48).astype(int) 
dados_combinados['tempo_72']=(dados_combinados['tempo']==72).astype(int) 
dados_combinados

"""**Modelo de Machine Learning:**

**“Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed” - (definição clássica de Arthur Samuel, cientista da computação, 1959)**

Problemas a serem resolvidos com ML:

Categóricos:

1) Dado os experimentos, predizer se algum experimento ativou ou não algum MOA - Classificação binária.

2) Dado os experimentos, descobrir se um determinado MOA foi ativado, recebendo como resposta, o composto (experimento) relacionado - Classificação multiclasse.

Aqui, como um composto pode acionar mais de um mecanismo, tem-se uma classificação multilabel (quando uma única instância pode ter mais de uma classe associada) e, através de um algoritmo de Machine Learning é possível resolver este problema: **não somente ter como retorno se um mecanismo de ação foi ativado mas qual ou quais são estes mecanismos.**

**Estruturação dos dados:**

É importante lembrar que as bases de dados estão separadas com um propósito. A segunda base dados_resultados é como se fosse a resposta da primeira e foi construída por cientistas que analisaram o efeito de um determinado composto nos mais de 700 genes. Esse conhecimento, virou uma base de dados com o passar dos anos e é fruto de análise científica.

E o papel de um modelo de ML neste caso é, a partir de todo esforço humano empenhado por vários anos para entender e tabular qual efeito de um composto quimíco em uma determinada expressão gênica, ser treinado e aprender, ou seja, ser capaz de produzir resultados compatíveis com aqueles feitos pelos(as) próprios(as) cientistas.

**Problema de ML:**

**Classificação binária: dado os experimentos, predizer se QUALQUER mecanismo de ação foi ativado ou não.**

Basicamente, o modelo terá de fazer predições compatível com a coluna da base de dados dados_combinados, a *ativo_moa*.

As etapas lógicas do processo são:

Dado um composto (experimento considerando informações de como esse composto foi ministrado) -> temos a assinatura celular (resposta de genes e células) -> analisamos os mecanismos de ação ativados (MOA);

Mas, a pergunta a ser respondida é: **Dado um composto e uma assinatura celular, houve algum MOA ativado?** 

Então, as etapas lógicas passam a ser:

**Composto -> assinatura celular -> MOA ativado?**

Aprendendo a partir da base de dados: Cada composto representa uma linha da tabela.

Composto 1 -> Assinatura A -> MoA = 1 \
Composto 2 -> Assinatura B -> MoA = 0 \
Composto 3 -> Assinatura C -> MoA = 1 \
... \
Composto N -> Assinatura N -> MoA = 0 \

Ou seja, toda a base de dados dados_combinados será a fonte de aprendizado do modelo de ML. Onde, cada experimento (linha) representa um exemplo (assinatura) qu engloba todas as informações necessárias para criar a classificação binária e, terá como variável resposta, também chamada de target, a coluna ativo_moa, uma variável binária (0, 1).

Por fim, o modelo deverá ser capaz de resolver o seguinte problema:

**Composto candidato (experimento com informações de dose, tempo e tipo de composto) -> Assinatura X -> MoA = 1 OU MoA = 0?**

**Técnica de ML: Regressão Logística**

Existem diversas técnicas de ML que são capazes de solucionar esse problema, porém vamos usar a Regressão Logística através do Scikit-Learn.

https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

Divisão do dataset entre treino e teste:

Treino: Conjunto de dados de aprendizado.

Teste: Conjunto de validação do que foi treinado.

Para fazer a divisão da base, é necessário definir o x e o y. Um modelo matemático, define y (variável dependente) em função de x (variável independente), ou seja, *f(x) = y*. 

Neste projeto, o y será o target *ativo_moa* e, ele será definido a partir de uma assinatura (conjunto composto por g + c ou expressão gênica + viabilidade celular). A informação anterior à assinatura, como informações do composto, não é utilizada em x visto que essas informações do composto (tipo, dose e tempo) geram a assinatura, ou seja, essas informações estão implícitas na assinatura pois são responsáveis por gerarem essa resposta.

Assim, teremos:

x = dados_combinados.select_dtypes('float64')  ->  toda a base de dados que tem os valores com o formato *float64*, no caso todas as variáveis *g* e *c*
 
y = dados_combinados['ativo_moa']  ->  apenas a coluna target *ativo_moa*

**Divisão do dataset:**

Para o train_test_split define-se:

x_treino, x_teste, y_treino, y_teste

E a função receberá como parâmetro:

train_test_split(x, y, test_size = 0.2)

Onde,

x -> base de dados definida como x, no caso todas as variáveis *g* e *c*
 
y -> variável resposta, no caso *ativo_moa*
 
teste_size = 0.2 -> tamanho para a base de teste. A proporção entre treino e teste varia de acordo com o volume de dados disponível. Mas, usualmente, encontramos proporções 30/70, 25/75 ou 20/80. Aqui, definimos como 0,2 ou 20%, isso significa que a base de treino será composta pelos 80% restante.
"""

dados_novos.head()

dados_resultados.head()

dados_combinados.head()

x = dados_combinados.select_dtypes('float64')
y = dados_combinados['ativo_moa']

x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=376)

"""**Treino do modelo de ML:**

Modelo de regressão logística *modelo_rlogistica* com max_iter = 1000.

Ajuste do modelo com modelo_rlogistica.fit(x_treino, y_treino).

Função modelo_rlogistica.score(x_teste, y_teste) para verificar como o modelo ajustado está se saindo nos dados de teste. O score() calcula a acurácia, ou seja, quantas predições o modelo acertou na base de teste.

**Como resultado, temos o valor da acurácia: ~0,627. Então, conclui-se que o modelo está acertando ~62% das previsões (considerando 100 experimentos, o modelo acertaria 62 casos e erraria 38 casos).**

**Mas, como podemos estabelecer se este é um bom valor de acurácia ou não?**
"""

##Modelo de Regressão Logística
modelo_rlogistica = LogisticRegression(max_iter=1000)
modelo_rlogistica.fit(x_treino, y_treino) #treino
modelo_rlogistica.score(x_teste, y_teste) #predição e calculo de acurácia

"""**Baseline para comparação:**

O Scikit-Learn possui alguns algoritmos que implementam modelos menos complexos e que podem ser usados como base comparativa, como o DummyClassifier.

O processo para ajustar este modelo é muito parecido com o ajuste do modelo de regressão logística: divide-se a base em treino e teste, ajusta-se os dados de treino e, ao final, calcula-se a acurácia com o conjunto teste.

Ao instanciar o DummyClassifier, é necessário definir a estratégia que ele usará para ajustar o modelo. Neste caso, definimos que a estratégia será os *dados mais frequentes*, isso quer dizer que: dado o valor mais frequente da variável resposta (ativo_moa), o modelo Dummy vai chutar que todos os eventos da base de dados assumem aquele valor no target. Assim, tem-se: DummyClassifier('most_frequent').

Para calcular a acurácia, utilizamos outra estratégia, a função *accuracy_score* também do Scikit-Learn. Ela recebe como parâmetros a base teste da variável resposta (y_teste) e as previsões do modelo que, até o momento ainda não forma calculadas. Para calcular as previsões, usa-se o .predict() da mesma biblioteca que, recebe como parâmetro a base x_teste. Por fim, o cálculo da acurácia será:

previsao_dummy = modelo_dummy.predict(x_teste)
accuracy_score(y_teste, previsao_dummy)

**A acurácia do DummyClassifierfoi de ~60,7%, isso significa que o modelo LogisticRegression teve um desempenho um pouco melhor.**
"""

modelo_dummy = DummyClassifier('most_frequent')
modelo_dummy.fit(x_treino, y_treino) #treino
previsao_dummy = modelo_dummy.predict(x_teste) #predição
accuracy_score(y_teste, previsao_dummy) #calculo de acurácia

"""A acurácia do DummyClassifier pode ser entendida através do value_counts normalizado, o qual representa a proporção entre a classe 0 e a classe 1. 

Essa proporção é de 60/30, ou seja, o valor mais frequente (estratégia usada no DummyClassifier) representa 60% da base de dados. Isso quer dizer que, caso o modelo chutasse a mesma classe para todos os eventos da base de teste, teríamos um acerto de 60% dos casos.
"""

dados_combinados['ativo_moa'].value_counts(normalize=True)

"""**Garantindo predições iguais:**
Toda vez que a regressão logística ou o dummy classifier são executados, recebemos como retorno um valor diferente de acurácia, apesar de em muitos casos, serem próximos.

O *train_test_split* divide a base de dados em **subconjuntos aleatórios** de treino e teste. Isso significa que toda vez que a função de split for executada, o retorno será diferente.

Assim, o parâmetro random_state = n é utilizado para garantir que a saída de todas as execuções será igual, ou seja, sua divisão será sempre a mesma. Não importa qual o número utilizado no random_state, o importante é que sempre será retornada a mesma saída.

**Garantindo a proporção original do conjunto de dados:**

Além do random_state, o stratify é outro parâmetro importante que deve ser levado em consideração na divisão da base de dados.

Se repararmos na divisão da variável *ativo_moa*, entre true e false, percebemos que segue um balanceamento 60/40. 

Assim, é interessante que as bases de treino e teste sigam, além de uma divisão reprodutível (garantida com random_state), a proporção original do conjunto de dados. 

Portanto, atribui-se stratify = coluna, onde coluna = nome da coluna que o stratify deve levar em consideração a proporção de classes. No caso, adoatmos stratify = y, pois y é a variável resposta e, é dela que o stratify deve considerar a proporção: 60/40.

Esses parâmetros são úteis, porque garantem que os resultados sejam reproduzíveis e compatíveis, independente do modelo de ML utilizado para treinar e testar a partir desta divisão.

Ou seja, ao final, o train_teste_split ficará:

**x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=376)**

**Técnica de ML: Árvore de Decisão**

Utilização de outra técnica de ML visando a comparação de resultados.

A sequência lógica para ajustar esse novo modelo é similar aos anteriores: define-se as bases x e y, aplica-se o train_test_split, declara-se e treina o modelo, e verifica-se a acurácia.

O modelo de árvore de decisão utilizado é implementado no módulo DecisionTreeClassifier do Scikit-Learn. 

Adotou-se um modelo de árvore com max_depth = 3.

**Como resultado, temos uma acurácia de ~0,61% e, é um pouco menos do que a acurácia obtida com a regressão logística.**
"""

modelo_arvore = DecisionTreeClassifier(max_depth = 3)
modelo_arvore.fit(x_treino, y_treino)
modelo_arvore.score(x_teste, y_teste)

"""**Entendendo a Árvore de Decisão:**

Parâmetro max_depth = 3.

A figura é dividida em 4 níveis:

* O primeiro nível é composto pelo nó raíz, que tem como regras, as melhores features (atributos) que podem dividir a base de dados em dois conjuntos distintos (mecanismo de ação ativado ou não ativado).

* Entre o primeiro e o segundo nível (e nos demais níveis), aparecem duas setas: dois possíveis caminhos. Essas setas são chamadas de ramos e subdividem o nível acima em dois outros conjuntos que separam novamente os dados em mecanismo de ação ativado ou não ativado, a partir de uma decisão.

* O último nível da árvore, apresenta n nós (folhas) que apresentam características que devem ser levadas em conta na hora da classificação e se dividem em *class = ativado* e *class = não ativado*.

O parâmetro max_depth representa a profundidade da árvore, que assume 3 níveis de decisão a partir da raíz.

**Ilustração da árvore de decisão com profundidade 3:**
"""

fig, ax = plt.subplots(figsize=(15, 10), facecolor='k')
tree.plot_tree(modelo_arvore,
               ax=ax,
               fontsize=10,
               rounded=True,
               filled=True,
               feature_names=x_treino.columns,
               class_names=['Não Ativado', 'Ativado'])

plt.show()

"""O desempenho do modelo com apenas 3 camadas de decisão não foi tão satisfatório assim. 

Por isso, o max_depth deve ser variado dentro de um intervalo de valores:

No caso abaixo, entre 1 e 14 camadas.
"""

teste=[]
treino=[]
for i in range(1,15):
    modelo_arvore = DecisionTreeClassifier(max_depth = i)
    modelo_arvore.fit(x_treino, y_treino)
    teste.append(modelo_arvore.score(x_teste, y_teste))
    treino.append(modelo_arvore.score(x_treino, y_treino))

for i in range(len(treino)): print('profundidade da árvore:', i+1, 'score treino:', treino[i], 'score teste:', teste[i]);

"""**Problema de overfitting:**

Observando as diferenças entre os scores de treino e teste, percebe-se que inicialmente os valores de treino e teste são muito próximos mas, conforme a profundiade aumenta, o valor da acurácia para os dados de treino aumentam muito enquanto, esse mesmo valor para os dados de teste, vai caindo (a diferença entre eles aumenta).

Isso significa que, conforme a profundidade da árvore de decisão aumenta, a classificação para os dados de treino ficam muito boas, pois ela consegue captar muito bem as características desses dados em particular. 

Em contrapartida, o modelo fica tão bom para os dados de treino que quando um novo conjunto de dados (teste) é apresentado, ele não consegue generalizar tão bem e assim, a acurácia vai caindo em relação ao conjunto de treino.

Esse problema de um modelo com performance muito boa nos dados de treino mas performance em queda nos dados de teste, é muito conhecido na ciência de dados e é chamado de **overfitting**.

Assim, apenas aumentar a profundidade da árvore não é suficiente para melhorar a acurácia do modelo, precisa-se de outras estratégias. Uma estratégia de ML mais robusta que pode ser utilizada consiste na Random Forest.
"""

[treino[i]-teste[i] for i in range(len(teste))] #diferenças entre as acurácias de treino e teste

plt.figure(figsize=(12, 8))
ax=sns.lineplot(x=range(1,15), y = teste, label='teste')
ax=sns.lineplot(x=range(1,15), y = treino, label='treino')
ax.set(xlabel='Profundidade árvore', ylabel='Score')

"""**Técnica de ML: Random Forest**

O modelo de Random Forest cria várias árvores de decisões na qual ele considera amostras aleatórias do conjunto de dados total para realizar as predições.
"""

modelo_randomforest = RandomForestClassifier()
modelo_randomforest.fit(x_treino, y_treino)
modelo_randomforest.score(x_teste, y_teste)

"""**Incrementando as features do modelo:**

Inclusão das features relacionadas aos experimentos: tratamento, dose e tempo.

Contudo, a função de Random Forest (RandomForestClassifier()) não aceita variáveis em formato string. Por isso, é preciso tratar as variáveis que são strings e transformá-las em números (ou no formato float64).

**Transformação de variáveis tipo string para numérico:**

Para fazer essa transformação, pode-se utilizar a função do Pandas get_dummies e nela, declara-se a coluna a ser transformada em dados numéricos. Por exemplo:

pd.get_dummies(dados_combinados['tratamento'])

Para fazer a transformação desejada, o get_dummies pega todas as categorias de uma variável e as transforma em novas colunas binárias. Por exemplo:

A variável tratamento apresenta duas categorias com_controle e sem_controle. O get_dummies cria duas novas colunas binárias e análogas as categorias.
"""

pd.get_dummies(dados_combinados['tratamento'])

pd.get_dummies(dados_combinados, columns=['tratamento', 'dose', 'tempo'])

"""**Base de dados com novas features:**

Como novas features, não mais consideraremos apenas os dados genéticos, mas também as demais variáveis de tratamento, dose e tempo. Serão ignoradas as seguintes variáveis:

'id'  ->  não será relevante nesse momento pois é somente um número de identificação;\

'n_moa'  ->  não será relevante nesse momento pois é a quantidade de MOAs ativados;\

'ativo_moa'  ->  variável resposta;\

'composto'  ->  não será relevante nesse momento pois identifica o composto usado e foge do objetivo do problema;
"""

dados_combinados.drop(['id', 'n_moa', 'ativo_moa', 'composto'], axis=1)

"""**Redefinindo a variável x e treinando o modelo com os diferentes modelos de ML:**

O modelo de Regressão Logística atingiu uma acurácia de ~66,0%, sendo melhor com essa nova base de dados.

O modelo atingiu uma acurácia de ~69,0%, também apresentando melhora de acurácia e superando os outros modelos.

O modelo atingiu uma acurácia de ~68,0%, melhorando a acurácia em relação à base anterior.

Assim, a base com as novas features de experimentos representa melhor o comportamento de ativação ou não ativação dos MOAs.

Contudo, esses modelos precisam ser melhor tunados para obterem melhores resultados.
"""

x = dados_combinados.drop(['id', 'n_moa', 'ativo_moa', 'composto'], axis=1)
x = pd.get_dummies(x, columns=['tratamento', 'dose', 'tempo'])
y = dados_combinados['ativo_moa']

x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=376)

modelo_rlogistica = LogisticRegression(max_iter=1000)
modelo_rlogistica.fit(x_treino, y_treino) #treino
scr=modelo_rlogistica.score(x_teste, y_teste) #predição e calculo de acurácia
print(scr)

modelo_arvore = DecisionTreeClassifier(max_depth = 3)
modelo_arvore.fit(x_treino, y_treino)
scr=modelo_arvore.score(x_teste, y_teste)
print(scr)

modelo_randomforest = RandomForestClassifier()
modelo_randomforest.fit(x_treino, y_treino)
scr=modelo_randomforest.score(x_teste, y_teste)
print(scr)